{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use\n",
    "\n",
    "Make sure you go trough all the blocks to initialize necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_extraction(sentence):\n",
    "    ignore = set(stopwords.words('english'))\n",
    "    words = re.sub(\"[^\\w]\", \" \",  sentence).split()\n",
    "    cleaned_text = '' \n",
    "    for w in words:\n",
    "        if w not in ignore:\n",
    "            cleaned_text += w.lower() + ' '\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def choose_type(q_id):\n",
    "    ans_data = df_ans[df_ans['Question_id'] == q_id]\n",
    "    q_row = df_qns[df_qns['Question_id'] == q_id].to_dict(orient='records')[0]\n",
    "    correct_answer = q_row['Correct_answer_choice']\n",
    "    num_students = len(ans_data)\n",
    "    \n",
    "    num_correct = len(ans_data[ans_data['Student_score_on_question'] == 1])\n",
    "    #If a few students answered correctly, we go for MC as we may not have enough correct options for SA\n",
    "    if num_correct < 2:\n",
    "        return 'MC'\n",
    "\n",
    "    if q_row['Question_type'] == 'MC':\n",
    "        \n",
    "        num_correct = q_row['Students_select_' + q_row['Correct_answer_choice']]\n",
    "        #If no students answered correctly, we go for MC as we have one correct option in df_qns\n",
    "        if num_correct == 0:\n",
    "            return 'MC'\n",
    "        \n",
    "        tmp = np.unique(ans_data['Student_choice_on_question'].values, return_counts=True)\n",
    "        clusters = dict(zip(tmp[0], tmp[1]))\n",
    "        if len(clusters) >= 3:\n",
    "            # If students gave enough incorrect answers (from at least 2 different clusters), we go for MC\n",
    "            return 'MC'\n",
    "        else:\n",
    "            # If students' icorrect answers are all related to the same option, we go for SA\n",
    "            return 'SA'\n",
    "\n",
    "    if q_row['Question_type'] == 'SA':\n",
    "        \n",
    "        tmp = np.unique(ans_data['Student_choice_on_question'].values, return_counts=True)\n",
    "        clusters = dict(zip(tmp[0], tmp[1]))\n",
    "        \n",
    "        subset_of_correct = 0\n",
    "        subset_of_incorrect = 0\n",
    "        num_part_correct = 0\n",
    "        for x in clusters:\n",
    "            if all([y in correct_answer.split(',') for y in x.split(', ')]):\n",
    "                subset_of_correct += 1\n",
    "                num_part_correct += clusters[x]\n",
    "            if not any([y in correct_answer.split(',') for y in x.split(',')]):\n",
    "                subset_of_incorrect += 1\n",
    "\n",
    "        if(subset_of_correct == 1 & num_part_correct < num_students / 4):\n",
    "            return 'MC'\n",
    "        else:\n",
    "            return 'SA'        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_candidates(target, candidates, k, regime = 'dir'):\n",
    "        \n",
    "    candidates_post = [x for x in candidates if len(x.split(' ')) > 5]\n",
    "    if len(candidates_post) < k:\n",
    "        candidates_post = candidates\n",
    "        \n",
    "    candidates_shorten = [word_extraction(x) for x in candidates_post]\n",
    "    \n",
    "    i1s = [opt_dict[word_extraction(t)] for t in target]\n",
    "    i2s = [ans_dict[x] for x in candidates_shorten]\n",
    "    distances = sum([cosine_similarities[i1, i2s] for i1 in i1s]) + 0.01\n",
    "    distances = distances / sum(distances)\n",
    "    \n",
    "    if regime == 'inv':\n",
    "        distances = (1 - distances) / (len(distances) - 1)\n",
    "    \n",
    "    flag = False\n",
    "    if len(candidates_post) < k:\n",
    "        flag = True\n",
    "    \n",
    "    options = np.random.choice([i for i in range(len(distances))], k, replace=flag, p=distances)\n",
    "    options_texts = [candidates_post[x] for x in options]\n",
    "    \n",
    "    return options_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_options_mcmc(q_id):\n",
    "    #correct options goes as a feedback\n",
    "    \n",
    "    ans_data = df_ans[df_ans['Question_id'] == q_id].reset_index(drop='True')\n",
    "    q_row = df_qns[df_qns['Question_id'] == q_id].to_dict(orient='records')[0]\n",
    "    correct_answer = q_row['Correct_answer_choice']\n",
    "    num_students = len(ans_data)\n",
    "    \n",
    "        \n",
    "    # We use correct option as a feedback in case student answers question incorrectly twice. We also show this\n",
    "    # if a student answered question correctly\n",
    "    feedback = [q_row['Choice_' + correct_answer + '_text']]\n",
    "\n",
    "\n",
    "    #################Choosing correct options#######################\n",
    "    # Now we need to choose 2 correct options for 2 retry\n",
    "\n",
    "    correct_options_texts = sample_candidates(feedback, \\\n",
    "                      ans_data[ans_data['Student_score_on_question'] == 1]['Answer_text'].values, 2)\n",
    "\n",
    "    #################Choosing incorrect options#######################\n",
    "\n",
    "    incorrect_groups = np.unique(ans_data['Student_choice_on_question'].values)\n",
    "    incorrect_groups = [x for x in incorrect_groups if x != correct_answer]\n",
    "\n",
    "    choices = {x : ans_data[ans_data['Student_choice_on_question'] == x]['Answer_text'].values \n",
    "               for x in incorrect_groups}\n",
    "    lens = [len(x) for x in choices]\n",
    "\n",
    "    if len(choices) == 3 :\n",
    "        incorrect_options_texts1 = sample_candidates([q_row['Choice_' + x + '_text']], choices[x], 1) \n",
    "                                    \n",
    "    elif len(choices) == 2:\n",
    "        if lens[0] > lens[1]:\n",
    "            x = incorrect_groups[0]\n",
    "            y = incorrect_groups[1]\n",
    "        else:\n",
    "            y = incorrect_groups[0]\n",
    "            x = incorrect_groups[1]\n",
    "        incorrect_options_texts1 = sample_candidates([q_row['Choice_' + x + '_text']], choices[x], 2) \n",
    "        incorrect_options_texts1 += sample_candidates([q_row['Choice_' + y + '_text']], choices[y], 1)\n",
    "    else:\n",
    "        x = incorrect_groups[0]\n",
    "        incorrect_options_texts1 = sample_candidates([q_row['Choice_' + x + '_text']], choices[x], 3)\n",
    "\n",
    "    incorrect_options_texts2 = [q_row['Choice_' + x  + '_text'] for x in ['A', 'B', 'C', 'D'] if x != correct_answer]\n",
    "\n",
    "    return {'attempt1.correct': [correct_options_texts[0]],\n",
    "            'attempt2.correct': [correct_options_texts[1]], \n",
    "            'attempt1.wrong': incorrect_options_texts1,\n",
    "            'attempt2.wrong': incorrect_options_texts2, \n",
    "            'feedback': feedback}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_options_sasa(q_id):\n",
    "    #correct options goes as a feedback\n",
    "    \n",
    "    ans_data = df_ans[df_ans['Question_id'] == q_id].reset_index(drop='True')\n",
    "    q_row = df_qns[df_qns['Question_id'] == q_id].to_dict(orient='records')[0]\n",
    "    correct_answer = q_row['Correct_answer_choice'].split(',')\n",
    "    num_students = len(ans_data)\n",
    "    \n",
    "        \n",
    "    # We use correct option as a feedback in case student answers question incorrectly twice. We also show this\n",
    "    # if a student answered question correctly\n",
    "    feedback = [q_row['Choice_' + x + '_text'] for x in correct_answer]\n",
    "    correct = []\n",
    "    wrong = []\n",
    "    partial = []\n",
    "    options_at_hand =  np.unique(ans_data['Student_choice_on_question'].values)\n",
    "    for x in options_at_hand:\n",
    "        if all([y in correct_answer for y in x.split(', ')]):\n",
    "            correct += [x]\n",
    "        elif not any([y in correct_answer for y in x.split(', ')]):\n",
    "            wrong += [x]\n",
    "        else:\n",
    "            partial += [x]\n",
    "            \n",
    "    c_count = sum([len(ans_data[ans_data['Student_choice_on_question'] == x]) for x in correct])\n",
    "    \n",
    "    if c_count > num_students*0.8:\n",
    "        n_corr = 3\n",
    "    else:\n",
    "        n_corr = 2\n",
    "    \n",
    "    ##############################Correct Options###################################\n",
    "            \n",
    "    if len(correct) == 1:\n",
    "        correct_options_texts = sample_candidates([feedback],\n",
    "                      ans_data[ans_data['Student_score_on_question'] == correct[0]]['Answer_text'].values, 2*n_corr)\n",
    "                        \n",
    "    if len(correct) == 2:\n",
    "        cl1 = ans_data[ans_data['Student_choice_on_question'] == correct[0]]['Answer_text'].values\n",
    "        cl2 = ans_data[ans_data['Student_choice_on_question'] == correct[1]]['Answer_text'].values\n",
    "        \n",
    "        if(len(cl1) < len(cl2)):\n",
    "            cl1, cl2 = cl2, cl1\n",
    "        \n",
    "        if(len(cl2) < n_corr):\n",
    "            idx1 = 2*n_corr - len(cl2)\n",
    "            idx2 = len(cl2)\n",
    "        else:\n",
    "            idx1 = n_corr\n",
    "            idx2 = n_corr\n",
    "            \n",
    "        \n",
    "        correct_options_texts = sample_candidates([q_row['Choice_' + x + '_text'] \n",
    "                                                   for x in correct[0].split(', ')], cl1, idx1)\n",
    "        correct_options_texts += sample_candidates([q_row['Choice_' + x + '_text'] \n",
    "                                                    for x in correct[1].split(', ')], cl2, idx2)\n",
    "        \n",
    "    if len(correct) == 3:\n",
    "        cl = [ans_data[ans_data['Student_choice_on_question'] == correct[i]]['Answer_text'].values for i in range(3)]\n",
    "        ind = sorted([0, 1, 2], key = lambda x: len(cl[x]), reverse=True)\n",
    "        \n",
    "        correct_options_texts = sample_candidates([q_row['Choice_' + x + '_text']\n",
    "                                                     for x in correct[ind[0]].split(', ')], cl[ind[0]], 2*n_corr - 3)\n",
    "        correct_options_texts += sample_candidates([q_row['Choice_' + x + '_text']\n",
    "                                                     for x in correct[ind[1]].split(', ')], cl[ind[1]], 2)\n",
    "        correct_options_texts += sample_candidates([q_row['Choice_' + x + '_text']\n",
    "                                                     for x in correct[ind[2]].split(', ')], cl[ind[2]], 1)\n",
    "    \n",
    "    \n",
    "    np.random.shuffle(correct_options_texts)\n",
    "    \n",
    "    \n",
    "    ##############################Incorrect Options##################################\n",
    "    \n",
    "    incorrect_options_texts2 = [q_row['Choice_' + x  + '_text'] for x in ['A', 'B', 'C', 'D'] \n",
    "                                if x not in correct_answer]\n",
    "    if n_corr == 3:\n",
    "        return{'attempt1.correct':  correct_options_texts[:n_corr], \n",
    "               'attempt2.correct':  correct_options_texts[n_corr:],  \n",
    "               'attempt1.wrong': [incorrect_options_texts2[0]], \n",
    "               'attempt2.wrong': [incorrect_options_texts2[1]], \n",
    "               'feedback': feedback}\n",
    "\n",
    "    wrong_options_texts = []\n",
    "\n",
    "    if len(wrong) > 0:\n",
    "        comp_wrong_options = []\n",
    "        for x in wrong:\n",
    "            comp_wrong_options += list(ans_data[ans_data['Student_choice_on_question'] == x]['Answer_text'].values)\n",
    "        if len(comp_wrong_options) > 1:\n",
    "            wrong_options_texts = np.random.choice(comp_wrong_options, 4-n_corr, replace=False)\n",
    "        else:\n",
    "            wrong_options_texts = [comp_wrong_options[0]]\n",
    "\n",
    "            \n",
    "    if len(wrong_options_texts) < 4-n_corr:\n",
    "        r_opt = 4-n_corr - len(wrong_options_texts)\n",
    "        part_wrong_options = []\n",
    "        for x in partial:\n",
    "            part_wrong_options += list(ans_data[ans_data['Student_choice_on_question'] == x]['Answer_text'].values)\n",
    "        wrong_options_texts += sample_candidates(incorrect_options_texts2, part_wrong_options, r_opt)\n",
    "            \n",
    "    return{'attempt1.correct': correct_options_texts[0:n_corr],\n",
    "           'attempt2.correct': correct_options_texts[n_corr:],\n",
    "           'attempt1.wrong': wrong_options_texts,\n",
    "           'attempt2.wrong': incorrect_options_texts2,\n",
    "           'feedback': feedback}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_options_mcsa(q_id):\n",
    "    ans_data = df_ans[df_ans['Question_id'] == q_id].reset_index(drop='True')\n",
    "    q_row = df_qns[df_qns['Question_id'] == q_id].to_dict(orient='records')[0]\n",
    "    correct_answer = q_row['Correct_answer_choice'].split(',')\n",
    "    num_students = len(ans_data)\n",
    "    \n",
    "    # We use correct option as a feedback in case student answers question incorrectly twice. We also show this\n",
    "    # if a student answered question correctly\n",
    "    feedback = [q_row['Choice_' + x + '_text'] for x in correct_answer]\n",
    "    \n",
    "    ##############################Chosing Correct Option################################\n",
    "    \n",
    "    cor_ans = ans_data[ans_data['Student_score_on_question'] == 1]['Answer_text'].values\n",
    "    cor_ans = [x for x in cor_ans if len(x.split(' ')) > 5]\n",
    "    cor_ans = sample_candidates(feedback, cor_ans, 4)\n",
    "    \n",
    "    ##############################Choosing Incorrect Option#############################\n",
    "    \n",
    "    incor_ans = ans_data[ans_data['Student_score_on_question'] == 0]['Answer_text'].values\n",
    "    incor_ans = [x for x in incor_ans if len(x.split(' ')) > 5]\n",
    "    incor_ans = sample_candidates(feedback, incor_ans, 1, 'inv')\n",
    "    \n",
    "    wrong_opt = [q_row['Choice_' + x + '_text'] for x in ['A', 'B', 'C', 'D'] if x not in correct_answer]\n",
    "    \n",
    "    incor_ans += [wrong_opt[0]]\n",
    "    \n",
    "    return{'attempt1.correct': cor_ans[0:2],\n",
    "           'attempt2.correct': cor_ans[2:],\n",
    "           'attempt1.wrong': incor_ans,\n",
    "           'attempt2.wrong': wrong_opt[1:],\n",
    "           'feedback': feedback}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_options_samc(q_id):\n",
    "    ans_data = df_ans[df_ans['Question_id'] == q_id].reset_index(drop='True')\n",
    "    q_row = df_qns[df_qns['Question_id'] == q_id].to_dict(orient='records')[0]\n",
    "    correct_answer = q_row['Correct_answer_choice'].split(',')\n",
    "    num_students = len(ans_data)\n",
    "    \n",
    "    feedback = [q_row['Choice_' + x + '_text'] for x in correct_answer]\n",
    "    \n",
    "    tmp = np.unique(ans_data['Student_choice_on_question'].values, return_counts=True)\n",
    "    clusters = dict(zip(tmp[0], tmp[1]))\n",
    "                \n",
    "    subset_of_correct = []\n",
    "    subset_of_incorrect = []\n",
    "    subset_part = []\n",
    "    num_part = []\n",
    "    num_correct = 0\n",
    "    num_incorrect = 0\n",
    "    for x in clusters:\n",
    "        if all([y in correct_answer for y in x.split(', ')]):\n",
    "            subset_of_correct += [x]\n",
    "            num_correct += clusters[x]\n",
    "        elif not any([y in correct_answer for y in x.split(',')]):\n",
    "            subset_of_incorrect += [x]\n",
    "            num_incorrect += clusters[x]\n",
    "        else:\n",
    "            subset_part += [x]\n",
    "            num_part += clusters[x]\n",
    "            \n",
    "    \n",
    "    \n",
    "    ##############################Chosing Correct Option################################\n",
    "\n",
    "    \n",
    "    cor_cand = []\n",
    "    \n",
    "    for x in subset_of_correct:\n",
    "        cor_cand += list(ans_data[ans_data['Student_choice_on_question'] == x]['Answer_text'].values)\n",
    "                    \n",
    "    correct_options_texts = sample_candidates(feedback, cor_cand, 2)\n",
    "    \n",
    "    ##############################Chosing inorrect Option################################\n",
    "    \n",
    "    part_cand = []\n",
    "    wrong_cand = []\n",
    "    \n",
    "    for x in subset_part:\n",
    "        part_cand += list(ans_data[ans_data['Student_choice_on_question'] == x]['Answer_text'].values)\n",
    "        \n",
    "    for x in subset_of_incorrect:\n",
    "        wrong_cand += list(ans_data[ans_data['Student_choice_on_question'] == x]['Answer_text'].values)\n",
    "        \n",
    "    wrong_options_given = [q_row['Choice_' + x + '_text'] for x in ['A', 'B', 'C', 'D'] if x not in correct_answer]\n",
    "    \n",
    "    wrong_options_text = []\n",
    "    if len(wrong_cand) >= 4:\n",
    "        wrong_options_text += sample_candidates(wrong_options_given, wrong_cand, 4)\n",
    "    elif len(wrong_cand) >= 0:\n",
    "        wrong_options_text += wrong_cand\n",
    "        \n",
    "    r_opt = 4 - len(wrong_options_text)\n",
    "    \n",
    "    if r_opt > 0:\n",
    "        wrong_options_text += sample_candidates(wrong_options_given, part_cand, r_opt)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return {'attempt1.correct': [correct_options_texts[0]], \n",
    "            'attempt2.correct': [correct_options_texts[1]], \n",
    "            'attempt1.wrong': wrong_options_text[:3],\n",
    "            'attempt2.wrong': wrong_options_given + [wrong_options_text[3]],\n",
    "            'feedback': feedback}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_questions(q):\n",
    "    text = '';\n",
    "    for i in q:\n",
    "        cur_q = q[i]\n",
    "        text += 'Question ' + str(i) + '(' + q[i]['type']+ ')' + '\\n\\n' + 'Attempt 1' + '\\n\\n'\n",
    "        for option in range(len(q[i]['attempt1.correct'])):\n",
    "            text += 'Option' + str(option + 1) + \" (correct): \" + q[i]['attempt1.correct'][option] + '\\n\\n'\n",
    "        for option in range(len(q[i]['attempt1.wrong'])):\n",
    "            text += 'Option' + str(option + 1 + len(q[i]['attempt1.correct'])) + \" (incorrect): \"  + q[i]['attempt1.wrong'][option] + '\\n\\n'\n",
    "        \n",
    "        text += 'Attempt 2 \\n\\n'\n",
    "        \n",
    "        for option in range(len(q[i]['attempt2.correct'])):\n",
    "            text += 'Option' + str(option + 1) + \" (correct): \" + q[i]['attempt2.correct'][option] + '\\n\\n'\n",
    "        for option in range(len(q[i]['attempt2.wrong'])):\n",
    "            text += 'Option' + str(option + 1 + len(q[i]['attempt2.correct'])) + \" (incorrect): \"  + q[i]['attempt2.wrong'][option] + '\\n\\n'\n",
    "            \n",
    "        text += 'Option(s) kept for feedback : '\n",
    "        \n",
    "        for option in q[i]['feedback']:\n",
    "            text += '(+)' + option + ' '\n",
    "        text += ' \\n\\n'\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_qns and df_ans, cosine_similarities, ans_dict and opt_dict  must be globally defined!\n",
    "def main():\n",
    "        \n",
    "    questions = {}\n",
    "    for index, row in df_qns.iterrows():\n",
    "        idx = row['Question_id']\n",
    "        new_type = choose_type(idx)\n",
    "        if new_type == 'MC' and row['Question_type'] == 'MC':\n",
    "            questions[idx] = select_options_mcmc(idx) \n",
    "            questions[idx]['type'] = new_type\n",
    "        if new_type == 'SA' and row['Question_type'] == 'MC':\n",
    "            questions[idx] = select_options_mcsa(idx)\n",
    "            questions[idx]['type'] = new_type\n",
    "        if new_type == 'MC' and row['Question_type'] == 'SA':\n",
    "            questions[idx] = select_options_samc(idx)\n",
    "            questions[idx]['type'] = new_type\n",
    "        if new_type == 'SA' and row['Question_type'] == 'SA':\n",
    "            questions[idx] = select_options_sasa(idx)\n",
    "            questions[idx]['type'] = new_type\n",
    "    return questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entry point\n",
    "\n",
    "In the block below\n",
    "- regime:  development vs validation\n",
    "- df_ans: must be dataset with answers\n",
    "- df_qns: must be a dataset with questions\n",
    "\n",
    "Run all the block and you will see what the algo selects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regime = 'development'\n",
    "df_ans = pd.read_csv('Answers_data_prj3_update2.csv')\n",
    "df_qns = pd.read_csv('Questions_data_prj3.csv')\n",
    "\n",
    "#df_ans = pd.read_csv('ans_val.csv')\n",
    "#df_qns = pd.read_csv('q_val.csv')\n",
    "\n",
    "\n",
    "# The next line are necessary, because development and validations sets do not follow the same format!\n",
    "\n",
    "if regime == 'development':\n",
    "    df_qns.at[0, 'Question_type'] = 'MC' # This line must be applied to development set only!\n",
    "    df_qns.at[1, 'Question_type'] = 'SA' #\n",
    "\n",
    "if regime == 'validation':\n",
    "    df_qns.at[0, 'Correct_answer_choice'] = 'A,C'\n",
    "    \n",
    "    for i in range(len(df_ans)):\n",
    "        x = df_ans.at[i, 'Student_choice_on_question'].split(',')\n",
    "        if(len(x) == 2):\n",
    "            df_ans.at[i, 'Student_choice_on_question'] = x[0] + ', ' + x[1]\n",
    "        if(len(x) == 3):\n",
    "            df_ans.at[i, 'Student_choice_on_question'] = x[0] + ', ' + x[1]  + ', ' + x[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MAKE SURE YOUR RUN THIS\n",
    "allsentences = []\n",
    "for i in range(len(df_qns)):\n",
    "    allsentences += df_qns.iloc[i][['Choice_A_text', 'Choice_B_text', 'Choice_C_text', 'Choice_D_text']].tolist()\n",
    "allsentences += df_ans['Answer_text'].tolist()\n",
    "\n",
    "allsentences = [word_extraction(x) for x in allsentences]\n",
    "vectorizer = TfidfVectorizer()\n",
    "tf_idf = vectorizer.fit_transform(allsentences)\n",
    "\n",
    "ans_dict = {x : i for (i, x) in enumerate(allsentences)}\n",
    "\n",
    "opt_dict = {x : i for (i, x) in enumerate(allsentences[: 4 * len(df_qns)])}\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "tf_idf = vectorizer.fit_transform(allsentences)\n",
    "\n",
    "cosine_similarities = linear_kernel(tf_idf, tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1(SA)\n",
      "\n",
      "Attempt 1\n",
      "\n",
      "Option1 (correct): Rajeev is getting a lot of practice, but he should ask an art instructor each day for feedback on how well he drew the day’s portrait\n",
      "\n",
      "Option2 (correct): Despite doing so much practice, there is no one to give Rajeev feedback on his errors and remedial training based on that feedback. So while Rajeev is practicing a lot, he is not doing deliberate practice which focuses on correcting his errors and then improving his skill.\n",
      "\n",
      "Option3 (incorrect): The task of creating a portrait is a complex one and should be studied step by step rather than in full. Hence, Rajeev should identify what parts of the portrait are problematic and practice them regularly instead of drawing new full portrait every day.\n",
      "\n",
      "Option4 (incorrect): Rajeev is practicing different tasks every day, so his practice isn’t deliberate. He should try and draw the same portrait every day\n",
      "\n",
      "Attempt 2 \n",
      "\n",
      "Option1 (correct): He is not doing deliberate practice. B/c there is no feedback provided.\n",
      "\n",
      "Option2 (correct): He is not doing deliberate practice. That is, his practice might not be focused on the part that needs improvement, there is no feedback on his performance from experts.\n",
      "\n",
      "Option3 (incorrect): Rajeev is practicing for too short a time. He should practice for a longer period of time\n",
      "\n",
      "Option4 (incorrect): Rajeev’s practice sessions are always in the morning; he should try varying his practice schedule\n",
      "\n",
      "Option(s) kept for feedback : (+)Rajeev is getting a lot of practice, but he should ask an art instructor each day for feedback on how well he drew the day’s portrait  \n",
      "\n",
      "Question 2(SA)\n",
      "\n",
      "Attempt 1\n",
      "\n",
      "Option1 (correct): No because, he is lacking (1) explicit instructions about the best method (2) supervised by a teacher to diagnose erorrs because he s diagnosing them himself and (3) immediate feedback as he watched the videos at the end of the day and gives himself feedback\n",
      "\n",
      "Option2 (correct): The feedback needs to be given by an external agent\n",
      "\n",
      "Option3 (correct): No, because there is not an external agent providing instructive and immediate feedback in Dan's practice\n",
      "\n",
      "Option4 (incorrect): Yes, because he is practicing a specific skill with rich feedback\n",
      "\n",
      "Attempt 2 \n",
      "\n",
      "Option1 (correct): No, because he doesn't have an external mentor to guide the practice.\n",
      "\n",
      "Option2 (correct): Not receiving immediate feedback may make Rajeev not yield an improvement.\n",
      "\n",
      "Option3 (correct): Not exactly. To engage in deliberate practice, one must be given explicit instruction about the best method. Since Dan is simply reflecting on his own method and has never compared it with a best method given to him by an expert, this step is not met. You could perhaps argue that the second component of deliberate practice is met, he is his own teacher and diagnosis his own errors. But without the first point, this is meaningless. Finally, the third part of deliberate practice of getting informative feedback and remedial training could be argued that he's doing this for himself. But again, without being able to compare it with a best method, this is meaningless.\n",
      "\n",
      "Option4 (incorrect): Yes, because he is practicing a specific skill with knowledge of the results of his previous attempts\n",
      "\n",
      "Option(s) kept for feedback : (+)No, because he is not getting task feedback from an external agent (+)No, because he is not able to practice corrections immediately (he must wait till the next day)  \n",
      "\n",
      "Question 3(SA)\n",
      "\n",
      "Attempt 1\n",
      "\n",
      "Option1 (correct): You did a great job putting efforts into practice and it paid off!\n",
      "\n",
      "Option2 (correct): Great job. Keep working and putting effort, you will improve more quickly.\n",
      "\n",
      "Option3 (incorrect): Amazing job! Great persistent on your learning.\n",
      "\n",
      "Option4 (incorrect): One of the most important things about growth mindset is giving feedback on the task that Mark is doing and not on his own personality of him being a talented musician. One growth mindset instruction his instructor could give him is \"Great work in your performance today. Keep up with your perseverance.\"\n",
      "\n",
      "Attempt 2 \n",
      "\n",
      "Option1 (correct): Citing the recommended paper, \"Growth-mind-set interventions convey that intelligence can grow when students work hard on challenging tasks—and thus that struggle is an opportunity for growth, not a sign that a student is incapable of learning.\" Given that, option C seems correct as it shows that through struggling, Mark managed to improve his ability to keep the right rhythm.\n",
      "\n",
      "Option2 (correct): Great, you are doing well on this song because of your hard practice. You could do better on other songs and more complex skills if you continue to practice like this.\n",
      "\n",
      "Option3 (incorrect): You are a talented musician\n",
      "\n",
      "Option4 (incorrect): Amazing job!\n",
      "\n",
      "Option(s) kept for feedback : (+)Great persistent on your learning (+)Well done keeping the right rhythm  \n",
      "\n",
      "Question 4(MC)\n",
      "\n",
      "Attempt 1\n",
      "\n",
      "Option1 (correct): No. Though it teaches the konwlegde in a better way, it does not share any knowledge about mindsets, nor the malleable nature of intelligence.\n",
      "\n",
      "Option2 (incorrect): Yes, students are encouraged to learn , express, they are seeing others rely on themselves and see themselves improve.\n",
      "\n",
      "Option3 (incorrect): According to the reading, Carlos changed his mindset because his groupmates think he was someone they could work with and someone they could appreciate.\n",
      "\n",
      "Option4 (incorrect): Yes, for example carlos, have developed a growth-mindset, while he thought he was stupid he later think he is smart.\n",
      "\n",
      "Attempt 2 \n",
      "\n",
      "Option1 (correct): No, because it doesn’t implicate how the brain works, and the malleable nature of intelligence\n",
      "\n",
      "Option2 (incorrect): Yes, because it shows students that they can grow in their abilities\n",
      "\n",
      "Option3 (incorrect): Yes, because it shows students that other students in their group can grow in their abilities\n",
      "\n",
      "Option4 (incorrect): No, because while it shows students that they can grow abilities in one subject, it leaves them uncertain about whether they can grow abilities in other subjects\n",
      "\n",
      "Option(s) kept for feedback : (+)No, because it doesn’t implicate how the brain works, and the malleable nature of intelligence  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(print_questions(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#with open('dev.pickle', 'wb') as handle:\n",
    "#   pickle.dump(q, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "#with open('dev.pickle', 'rb') as handle:\n",
    "#    q = pickle.load(handle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py36)",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
